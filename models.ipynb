{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "261dde76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    Column, Integer, String, Text, ForeignKey, DateTime, Boolean, Enum, Index, Table, UniqueConstraint, JSON\n",
    ")\n",
    "from sqlalchemy.orm import relationship, declarative_base, Session\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import func\n",
    "from datetime import datetime\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import boto3\n",
    "import enum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcda186",
   "metadata": {},
   "source": [
    "# Step 0. Imports & Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-21 14:00:55,055 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-21 14:00:55,055 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-21 14:00:55,056 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-21 14:00:55,056 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-21 14:00:55,057 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-21 14:00:55,057 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-21 14:00:55,058 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-21 14:00:55,058 INFO sqlalchemy.engine.Engine SELECT version();\n",
      "2025-09-21 14:00:55,058 INFO sqlalchemy.engine.Engine [generated in 0.00052s] {}\n",
      "‚úÖ Connected to: PostgreSQL 14.18 (Homebrew) on aarch64-apple-darwin23.6.0, compiled by Apple clang version 16.0.0 (clang-1600.0.26.6), 64-bit\n",
      "2025-09-21 14:00:55,059 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "# from sqlalchemy import create_engine, text\n",
    "\n",
    "# # load the .env file\n",
    "# load_dotenv()\n",
    "\n",
    "# # get database url\n",
    "# DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "# engine = create_engine(DATABASE_URL, echo=True)\n",
    "\n",
    "# with engine.connect() as conn:\n",
    "#     result = conn.execute(text(\"SELECT version();\"))\n",
    "#     print(\"‚úÖ Connected to:\", result.scalar())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0172b",
   "metadata": {},
   "source": [
    "### CAUTION: SQLAlchemy‚Äôs in-memory registry.\n",
    "When you re-run your model definitions (class Project(Base) etc.), SQLAlchemy thinks you‚Äôre trying to define the same table again in the same Python session.\n",
    "\n",
    "Fixes:\n",
    "\n",
    "* Restart the kernel (clean slate).\n",
    "\n",
    "* Or run Base.metadata.clear() before re-defining models.\n",
    "\n",
    "* Or (not recommended for production, but useful in notebooks) add:    \n",
    "\n",
    "`__table_args__ = {\"extend_existing\": True}`    \n",
    "\n",
    "inside each model.    \n",
    "\n",
    "**Potential problems of 3rd option-- Silent overwrites**    \n",
    "\n",
    "If you redefine a model with different column definitions, SQLAlchemy will happily overwrite the in-memory Python mapping.    \n",
    "\n",
    "But the database table itself is unchanged ‚Äî unless you drop/recreate or run a migration.    \n",
    "\n",
    "This can cause a mismatch: your Python code thinks a column exists (or has a new type), but the real Postgres table does not.    \n",
    "\n",
    "### My own suggestion:    \n",
    "#### During prototyping stage:         \n",
    "* use `__table_args__ = {\"extend_existing\": True}` for each model;\n",
    "    \n",
    "#### When your schema stabilizes and you‚Äôre preparing for AWS deployment:    \n",
    "1. Move your models into models.py (or a models/ package).\n",
    "\n",
    "        Delete __table_args__ = {\"extend_existing\": True} from each model.\n",
    "        Define Base = declarative_base() once at the top.\n",
    "\n",
    "2. Add Alembic to manage schema evolution:\n",
    "\n",
    "    `pip install alembic`    \n",
    "\n",
    "    `alembic init migrations`    \n",
    "\n",
    "* Configure alembic.ini with your DATABASE_URL.   \n",
    "\n",
    "* In env.py, set target_metadata = Base.metadata.\n",
    "\n",
    "3. Whenever you change a model:\n",
    "\n",
    "    `alembic revision --autogenerate -m \"describe change\"`\n",
    "   \n",
    "    `alembic upgrade head`\n",
    "\n",
    "This will safely apply only the changes needed, without dropping your tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc7161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base class\n",
    "Base = declarative_base() \n",
    "\n",
    "#---\n",
    "# It creates a registry (Base.metadata) that will hold all the tables you define.\n",
    "# Every time you define a model (class Project(Base): ...), that model‚Äôs table gets registered into Base.metadata.tables.\n",
    "#---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef16ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base.metadata.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bd9ed2",
   "metadata": {},
   "source": [
    "# Step 1. Enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Enums\n",
    "# --------------------------\n",
    "\n",
    "## 1.1 ProjectStatus\n",
    "class ProjectStatus(enum.Enum):\n",
    "    draft = \"draft\"                  # project created, requirements being defined\n",
    "    ready_for_annotation = \"ready_for_annotation\"  # files uploaded, jobs not started\n",
    "    in_progress = \"in_progress\"      # annotation jobs are running\n",
    "    completed = \"completed\"          # all jobs done\n",
    "    archived = \"archived\"            # project closed, read-only\n",
    "\n",
    "## 1.2 FileStatus (file lifecycle)\n",
    "class FileStatus(enum.Enum):\n",
    "    pending = \"pending\"\n",
    "    ready_for_annotation = \"ready_for_annotation\"\n",
    "    in_progress = \"in_progress\"\n",
    "    completed = \"completed\"\n",
    "    archived = \"archived\"\n",
    "\n",
    "## 1.3 FileType\n",
    "class FileType(enum.Enum):\n",
    "    dataset = \"dataset\"\n",
    "    requirement = \"requirement\"\n",
    "    report = \"annotation_results\"\n",
    "    llm_output = \"llm_output\"\n",
    "# Does our PM also needs to upload sliced file results? (NO currently)\n",
    "\n",
    "## 1.4 UserRole\n",
    "class UserRole(enum.Enum):\n",
    "    org_admin = \"org_admin\"       # customer admin\n",
    "    org_pm = \"org_pm\"             # customer project manager\n",
    "    our_pm = \"our_pm\"             # our company PM that manages annotation jobs & assigns annotators\n",
    "    annotator = \"annotator\"       # our company annotator\n",
    "    qc = \"qc\"                     # our company QC for annotation results review\n",
    "\n",
    "## 1.5 AnnotationJobStatus (job lifecycle)\n",
    "class AnnotationJobStatus(enum.Enum):\n",
    "    not_started = \"not_started\"\n",
    "    in_progress = \"in_progress\"\n",
    "    submitted = \"submitted\"\n",
    "    reviewed = \"reviewed\"\n",
    "\n",
    "## 1.6 ReviewStatus\n",
    "class ReviewStatus(enum.Enum):\n",
    "    pending = \"pending\"\n",
    "    approved = \"approved\"\n",
    "    rejected = \"rejected\"\n",
    "\n",
    "## 1.7 EntityType\n",
    "class EntityType(enum.Enum):\n",
    "    project = \"project\"\n",
    "    file = \"file\"\n",
    "    file_version = \"file_version\"\n",
    "    annotation_job = \"annotation_job\"\n",
    "\n",
    "## 1.8 EventType\n",
    "class EventType(enum.Enum):\n",
    "    uploaded = \"uploaded\"\n",
    "    reuploaded = \"reuploaded\"\n",
    "    annotation_started = \"annotation_started\"\n",
    "    annotation_completed = \"annotation_completed\"\n",
    "    reviewed = \"reviewed\"\n",
    "    deleted = \"deleted\"\n",
    "    status_changed = \"status_changed\"\n",
    "\n",
    "## 1.9 AssignmentRole\n",
    "class AssignmentRole(enum.Enum):\n",
    "    annotator = \"annotator\"\n",
    "    reviewer = \"reviewer\"\n",
    "    qc = \"qc\"   # quality control / audit\n",
    "\n",
    "## 1.10 Language (for AnnotationJob)\n",
    "class Language(enum.Enum):\n",
    "    en = \"en\"   # English\n",
    "    zh = \"zh\"   # Chinese\n",
    "    fr = \"fr\"   # French\n",
    "    de = \"de\"   # German\n",
    "    es = \"es\"   # Spanish\n",
    "    ar = \"ar\"   # Arabic\n",
    "\n",
    "## 1.11 Priority (for AnnotationJob)\n",
    "class JobPriority(enum.Enum):\n",
    "    low = \"low\"\n",
    "    medium = \"medium\"\n",
    "    high = \"high\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f55815",
   "metadata": {},
   "source": [
    "# Step 2. Association Tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce228213",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Table 'user_roles' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Association Tables\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 2.1 User <-> Role\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m user_roles \u001b[38;5;241m=\u001b[39m \u001b[43mTable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_roles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mInteger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mForeignKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser.user_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mondelete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCASCADE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mInteger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mForeignKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole.role_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mondelete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCASCADE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 2.2 Role <-> Permission\u001b[39;00m\n\u001b[1;32m     14\u001b[0m role_permissions \u001b[38;5;241m=\u001b[39m Table(\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole_permissions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     Base\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m     17\u001b[0m     Column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, Integer, ForeignKey(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole.role_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, ondelete\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCASCADE\u001b[39m\u001b[38;5;124m\"\u001b[39m), primary_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     18\u001b[0m     Column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpermission_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, Integer, ForeignKey(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpermission.permission_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, ondelete\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCASCADE\u001b[39m\u001b[38;5;124m\"\u001b[39m), primary_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kw)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Internship/Grandscale_Project/GrandscaleDB/env/lib/python3.10/site-packages/sqlalchemy/util/deprecations.py:281\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    275\u001b[0m         _warn_with_version(\n\u001b[1;32m    276\u001b[0m             messages[m],\n\u001b[1;32m    277\u001b[0m             versions[m],\n\u001b[1;32m    278\u001b[0m             version_warnings[m],\n\u001b[1;32m    279\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    280\u001b[0m         )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Internship/Grandscale_Project/GrandscaleDB/env/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:429\u001b[0m, in \u001b[0;36mTable.__new__\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;129m@util\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_params(\n\u001b[1;32m    423\u001b[0m     mustexist\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m )\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Internship/Grandscale_Project/GrandscaleDB/env/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:461\u001b[0m, in \u001b[0;36mTable._new\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m metadata\u001b[38;5;241m.\u001b[39mtables:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_existing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m extend_existing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[0;32m--> 461\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mInvalidRequestError(\n\u001b[1;32m    462\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already defined for this MetaData \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance.  Specify \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextend_existing=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto redefine \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions and columns on an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting Table object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m         )\n\u001b[1;32m    468\u001b[0m     table \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mtables[key]\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extend_existing:\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Table 'user_roles' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object."
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Association Tables\n",
    "# --------------------------\n",
    "\n",
    "# 2.1 User <-> Role\n",
    "user_roles = Table(\n",
    "    \"user_roles\",\n",
    "    Base.metadata,\n",
    "    Column(\"user_id\", Integer, ForeignKey(\"user.user_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    Column(\"role_id\", Integer, ForeignKey(\"role.role_id\", ondelete=\"CASCADE\"), primary_key=True)\n",
    ")\n",
    "\n",
    "# 2.2 Role <-> Permission\n",
    "role_permissions = Table(\n",
    "    \"role_permissions\",\n",
    "    Base.metadata,\n",
    "    Column(\"role_id\", Integer, ForeignKey(\"role.role_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    Column(\"permission_id\", Integer, ForeignKey(\"permission.permission_id\", ondelete=\"CASCADE\"), primary_key=True)\n",
    ")\n",
    "\n",
    "\n",
    "# One ExportLog may include multiple versions.\n",
    "# One FileVersion may appear in multiple exports\n",
    "class ExportedFile(Base):\n",
    "    __tablename__ = \"exported_file\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    export_id = Column(Integer, ForeignKey(\"export_log.export_id\", ondelete=\"CASCADE\"), primary_key=True)\n",
    "    file_version_id = Column(Integer, ForeignKey(\"file_version.version_id\", ondelete=\"CASCADE\"), primary_key=True)\n",
    "    included_at = Column(DateTime, default=func.now())\n",
    "\n",
    "    # Relationships\n",
    "    export = relationship(\"ExportLog\", back_populates=\"exported_files\")\n",
    "    file_version = relationship(\"FileVersion\", back_populates=\"exported_files\")\n",
    "\n",
    "# This table records which annotators have worked on this job before \n",
    "# (for feedback loops / reassignment tracking)\n",
    "job_previous_annotators = Table(\n",
    "    \"job_previous_annotators\",\n",
    "    Base.metadata,\n",
    "    Column(\"job_id\", Integer, ForeignKey(\"annotation_job.job_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    Column(\"user_id\", Integer, ForeignKey(\"user.user_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    Column(\"assigned_at\", DateTime, default=func.now())\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975f5e7",
   "metadata": {},
   "source": [
    "# Step 3: CORE TABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf2470",
   "metadata": {},
   "source": [
    "## 3.1 Project Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccc80484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/2287912739.py:6: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.Project, and will be replaced in the string-lookup table.\n",
      "  class Project(Base):\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Core Tables\n",
    "# -----------------------------\n",
    "    \n",
    "# Project Table\n",
    "class Project(Base):\n",
    "    __tablename__ = \"project\"\n",
    "    __table_args__ = (\n",
    "    UniqueConstraint(\"org_id\", \"name\", name=\"uq_org_project_name\"), # no two projects can share same name in one comp\n",
    "    Index(\"ix_project_status\", \"status\"), # speeds up dashboards like ‚Äúshow me all in-progress projects‚Äù.\n",
    "    Index(\"ix_project_is_active\", \"is_active\"), # speeds up ‚Äúonly show active projects‚Äù.\n",
    "    Index(\"ix_project_client_pm_id\", \"client_pm_id\"), # useful if query ‚Äúall projects started by this PM‚Äù.\n",
    "    Index(\"ix_project_org_id\", \"org_id\"), # useful if query ‚Äúall projects for this org‚Äù.\n",
    "    {\"extend_existing\": True} # delete\n",
    "    )\n",
    "\n",
    "    project_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    org_id = Column(Integer, ForeignKey(\"organization.org_id\"), nullable=False)\n",
    "    name = Column(String, nullable=False)\n",
    "    description = Column(Text, nullable=True) # longer desp than name\n",
    "\n",
    "    # plain text instructions\n",
    "    requirements_text = Column(Text, nullable=True)\n",
    "    # optional uploaded doc (PDF, Word, PPT, etc.)\n",
    "    # requirements_file_id = Column(Integer, ForeignKey(\"file.file_id\"), nullable=True)\n",
    "\n",
    "    # project status enum\n",
    "    status = Column(Enum(ProjectStatus, name=\"project_status_enum\"), default=ProjectStatus.draft)\n",
    "    \n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "\n",
    "    date_created = Column(DateTime, default=func.now(), nullable=False)\n",
    "    date_updated = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "    completed_at = Column(DateTime, nullable=True)\n",
    "    deleted_at = Column(DateTime, nullable=True) # when customer delete the project\n",
    "\n",
    "    # --- PM links ---\n",
    "    client_pm_id = Column(Integer, ForeignKey(\"user.user_id\"), nullable=False) # client PM\n",
    "    our_pm_id = Column(Integer, ForeignKey(\"user.user_id\"), nullable=True) # our PM\n",
    "\n",
    "    # --- Relationships ---\n",
    "    files = relationship(\"File\", back_populates=\"project\")             # all files\n",
    "    # convenience: only requirement files\n",
    "    requirement_files = relationship(\n",
    "        \"File\",\n",
    "        primaryjoin=\"and_(Project.project_id==File.project_id, File.file_type=='requirement')\",\n",
    "        viewonly=True\n",
    "    ) # only get files that accords with reqs\n",
    "    jobs = relationship(\"AnnotationJob\", back_populates=\"project\")     # all jobs\n",
    "    events = relationship(\"EventLog\", back_populates=\"project\")        # all events\n",
    "    organization = relationship(\"Organization\", back_populates=\"projects\")\n",
    "    client_pm = relationship(\"User\", foreign_keys=[client_pm_id], back_populates=\"client_projects\")\n",
    "    our_pm = relationship(\"User\", foreign_keys=[our_pm_id], back_populates=\"managed_projects\")\n",
    "    exports = relationship(\"ExportLog\", back_populates=\"project\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb06e27",
   "metadata": {},
   "source": [
    "## 3.2 File Table \n",
    "(currently only create one for all kinds of files' storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264bf1f",
   "metadata": {},
   "source": [
    "check the logic:\n",
    "1. files that clients uploaded, our PM needs to be able to view it so that they can further assign tasks;     \n",
    "2. files that clients uploaded, needs to be able to transport to LLM model(maybe it's sth in backend?)     \n",
    "3. annotator also needs relevant access, because for each task they needs the correspond raw file for annotation   \n",
    "4. quality checker also need them to check the work done by the annotator.     \n",
    "5. clients needs to be able to view the files they had uploaded and see the progress     \n",
    "6. organizations also needs to be able to view all the projects as well as all the files their company uploaded and created.    \n",
    "7. for the llm generated file, the annotator need to have access to it for corresponding task;     \n",
    "8. for annotated file uploaded by annotators, they needs to be able to send to quality checker;     \n",
    "9. the files that's approved by quality check needs to be able to back to customers     \n",
    "10. the organization needs to have access to all the final annotated files     \n",
    "11. the client PM needs to have access to the final annotated files that they uploaded     \n",
    "12. during uploading, each project allow customer to upload multiple files with different versions, only by clicking sth like \"confirmation\" will one project be created, and when project created, all files will be in pending status \n",
    "13. raw files can be deleted by customers before the task is processing (can be deleted during pending status)     \n",
    "14. one project only related to one client, but one client can relate to many projects     \n",
    "15. one file only related to one projects, but only projects can have multiple files,     \n",
    "16. when deleting a project, all the files under this project will be inactive,    \n",
    "17. both project manager in client company and the corresponding organization can have the access to delete the project(but client can only delete the project they created)    \n",
    "18. further link with file size and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/2956565627.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.File, and will be replaced in the string-lookup table.\n",
      "  class File(Base):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# File Table\n",
    "# --------------------------\n",
    "class File(Base):\n",
    "    __tablename__ = \"file\"\n",
    "    __table_args__ = (\n",
    "    UniqueConstraint(\"project_id\", \"name\", name=\"uq_project_file_name\"),\n",
    "    Index(\"ix_file_project_id\", \"project_id\"), # speeds up ‚Äúall files in project.‚Äù\n",
    "    Index(\"ix_file_status\", \"status\"), # speeds up ‚Äúall files ready for annotation.‚Äù\n",
    "    Index(\"ix_file_type\", \"file_type\"), # speeds up filtering datasets vs. requirements.\n",
    "    {\"extend_existing\": True},\n",
    ")\n",
    "\n",
    "\n",
    "    file_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    # descriptive file name (user-facing)\n",
    "    name = Column(String, nullable=False)\n",
    "    description = Column(Text, nullable=True)\n",
    "    uploaded_by = Column(Integer, ForeignKey(\"user.user_id\"), nullable=False)\n",
    "\n",
    "\n",
    "    # workflow state\n",
    "    status = Column(\n",
    "        Enum(FileStatus, name=\"file_status_enum\"),\n",
    "        default=FileStatus.pending,\n",
    "        nullable=False\n",
    "    )\n",
    "    # what kind of file this is (dataset, requirement, annotation_results, llm_nl)\n",
    "    file_type = Column(Enum(FileType, name=\"file_type_enum\"), nullable=False, default=FileType.dataset)\n",
    "\n",
    "    # audit timestamps\n",
    "    date_created = Column(DateTime, default=func.now(), nullable=False)\n",
    "    date_updated = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "    deleted_at = Column(DateTime, nullable=True)\n",
    "\n",
    "    # validate uploads by storage\n",
    "    size_bytes = Column(Integer, nullable=True)\n",
    "    mime_type = Column(String, nullable=True) # technical format\n",
    "\n",
    "    \n",
    "    # --- PM links ---\n",
    "    project_id = Column(Integer, ForeignKey(\"project.project_id\"), nullable=False)\n",
    "    # active version pointer\n",
    "    active_version_id = Column(Integer, ForeignKey(\"file_version.version_id\"), nullable=True)\n",
    "\n",
    "\n",
    "    # --- Relationships ---\n",
    "    uploader = relationship(\"User\", back_populates=\"uploaded_files\")\n",
    "    project = relationship(\"Project\", back_populates=\"files\")\n",
    "    versions = relationship(\"FileVersion\", back_populates=\"file\", cascade=\"all, delete-orphan\")\n",
    "    annotation_jobs = relationship(\"AnnotationJob\", back_populates=\"file\") \n",
    "    events = relationship(\"EventLog\", back_populates=\"file\")\n",
    "    active_version = relationship(\"FileVersion\", foreign_keys=[active_version_id], uselist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8ee00",
   "metadata": {},
   "source": [
    "## 3.3 File Version Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5063f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/1312225205.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.FileVersion, and will be replaced in the string-lookup table.\n",
      "  class FileVersion(Base):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# File Version Table\n",
    "# --------------------------\n",
    "class FileVersion(Base):\n",
    "    __tablename__ = \"file_version\"\n",
    "    __table_args__ = (\n",
    "        Index(\"ix_fileversion_file_id\", \"file_id\"),\n",
    "        {\"extend_existing\": True},\n",
    "    )\n",
    "\n",
    "    version_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # --- Parent link ---\n",
    "    file_id = Column(Integer, ForeignKey(\"file.file_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "    version_number = Column(Integer, nullable=False)  # 1, 2, 3‚Ä¶\n",
    "\n",
    "    # --- Storage info ---\n",
    "    storage_path = Column(String, nullable=False)   # MinIO/S3 key or path\n",
    "    checksum = Column(String, nullable=True)        # for integrity validation\n",
    "    size_bytes = Column(Integer, nullable=True)     # optional: store size at version-level\n",
    "    mime_type = Column(String, nullable=True)       # optional: file format at version-level\n",
    "\n",
    "    # --- Upload & provenance ---\n",
    "    uploaded_by = Column(Integer, ForeignKey(\"user.user_id\"), nullable=True)\n",
    "    uploaded_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)\n",
    "    # --- Lifecycle flags ---\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "\n",
    "    source_file_version_id = Column(Integer, ForeignKey(\"file_version.version_id\"), nullable=True)\n",
    "    generation_method = Column(\n",
    "        Enum(\"upload\", \"ocr\", \"llm\", name=\"generation_method_enum\"),\n",
    "        default=\"upload\",\n",
    "        nullable=False\n",
    "    )\n",
    "    llm_model = Column(String, nullable=True)       # e.g., \"gpt-4\", \"llama-3\"\n",
    "    llm_params = Column(JSON, nullable=True)        # parameters if generated by LLM\n",
    "\n",
    "\n",
    "    # --- Relationships ---\n",
    "    file = relationship(\"File\", back_populates=\"versions\")\n",
    "    source_version = relationship(\"FileVersion\", remote_side=[version_id])  # self-ref\n",
    "    events = relationship(\"EventLog\", back_populates=\"file_version\")        # version-level logs\n",
    "    exports = relationship(\n",
    "    \"ExportLog\",\n",
    "    secondary=\"exported_file\",\n",
    "    back_populates=\"file_versions\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # export_id = Column(Integer, ForeignKey(\"export_log.export_id\"), nullable=True)\n",
    "    exported_files = relationship(\n",
    "        \"ExportedFile\",\n",
    "        back_populates=\"file_version\",\n",
    "        cascade=\"all, delete-orphan\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6bd97",
   "metadata": {},
   "source": [
    "## 3.4 User Table\n",
    "\n",
    "\"user\" is a generic account table that represents any actor in the system:\n",
    "\n",
    "* Organization Admin (client company, oversees all projects).\n",
    "\n",
    "* Organization PM (client company, uploads datasets + requirements).\n",
    "\n",
    "* Our PM (your company, manages annotation jobs & assigns annotators).\n",
    "\n",
    "* Annotators (our company, upload results).\n",
    "\n",
    "* QC / Reviewers (our company, upload corrections).\n",
    "\n",
    "therefore, \"user\" here basically means everyone who logs in and interacts with the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db51942",
   "metadata": {},
   "source": [
    "product manager(our company):\n",
    "\n",
    "1. able to check the availability of the annotators and quality checkers\n",
    "2. able to check for each file, who and how many annotators have annotated that\n",
    "3. able to check the files uploaded by the client company‚Äôs PM or uploaded by the organization\n",
    "4. have access to projects and further assign annotators to each project to conduct annotation job \n",
    "5. have access to reassign annotators for same project\n",
    "6. have access to assign quality checker (one people can both be quality checker and annotator the same time, but for each project, if one person can either be quality checker or annotator)\n",
    "\n",
    "client company‚Äôs PM:\n",
    "\n",
    "1. able to upload files and create project\n",
    "2. able to view the files/projects they uploaded/created before\n",
    "3. not able to see the files/projects uploaded by others\n",
    "4. able to view the status of the projects/files\n",
    "5. able to resend files if the original project is pending(not in process)\n",
    "\n",
    "organization:\n",
    "\n",
    "1. able to upload files and create project\n",
    "2. able to view all the files/projects their company‚Äôs PM uploaded/created before\n",
    "\n",
    "LLM:\n",
    "\n",
    "1. get the files uploaded by client company‚Äôs PM\n",
    "2. generate natural language file according to the files\n",
    "\n",
    "our annotators:\n",
    "\n",
    "1. able to view the raw files and projects assigned to them that are uploaded by organization/ client company‚Äôs PM\n",
    "2. able to upload their finished annotated files\n",
    "3. able to get the natural language files generated by LLM\n",
    "\n",
    "our quality checker:\n",
    "\n",
    "1. able to view the raw files \n",
    "2. able to view the finished annotated files \n",
    "3. able to approve/ need modification of the annotated files and able to send back to annotators\n",
    "4. able to write down feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728faf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/1923528499.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.User, and will be replaced in the string-lookup table.\n",
      "  class User(Base):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# File User Table\n",
    "# --------------------------\n",
    "class User(Base):\n",
    "    __tablename__ = \"user\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    # --- Core fields ---\n",
    "    user_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    email = Column(String, unique=True, nullable=False, index=True)   # üîπ added index for fast lookups\n",
    "    role = Column(Enum(UserRole, name=\"user_role_enum\"), nullable=False)\n",
    "    \n",
    "    org_id = Column(\n",
    "        Integer,\n",
    "        ForeignKey(\"organization.org_id\", ondelete=\"SET NULL\"),  # better: keep user even if org deleted\n",
    "        nullable=True\n",
    "    )\n",
    "\n",
    "    availability = Column(JSON, nullable=True)\n",
    "\n",
    "    # --- Relationships ---\n",
    "    uploaded_files = relationship(\"File\", back_populates=\"uploader\")\n",
    "\n",
    "    events = relationship(\"EventLog\", back_populates=\"user\")\n",
    "\n",
    "    assignments = relationship(\n",
    "        \"Assignment\",\n",
    "        back_populates=\"user\",\n",
    "        cascade=\"all, delete-orphan\"\n",
    "    )\n",
    "\n",
    "    roles = relationship(\n",
    "        \"Role\",\n",
    "        secondary=user_roles,\n",
    "        back_populates=\"users\"\n",
    "    )\n",
    "\n",
    "    # project links\n",
    "    # Client-side PM <-> Project\n",
    "    projects = relationship(\"Project\", back_populates=\"client_pm\")\n",
    "    # make sure our PM has access to projects and further assign annotators\n",
    "    managed_projects = relationship(\"Project\", back_populates=\"our_pm\")\n",
    "\n",
    "    # Records which annotators have worked on this job before\n",
    "    # (for feedback loops / reassignment tracking)\n",
    "    previous_jobs = relationship(\n",
    "        \"AnnotationJob\",\n",
    "        secondary=\"job_previous_annotators\",\n",
    "        back_populates=\"previous_annotators\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(Base):\n",
    "    __tablename__ = \"user\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    # --- Core fields ---\n",
    "    user_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    email = Column(String, unique=True, nullable=False, index=True)\n",
    "    role = Column(Enum(UserRole, name=\"user_role_enum\"), nullable=False)\n",
    "\n",
    "    org_id = Column(\n",
    "        Integer,\n",
    "        ForeignKey(\"organization.org_id\", ondelete=\"SET NULL\"),\n",
    "        nullable=True\n",
    "    ) # better: keep user even if org deleted\n",
    "\n",
    "    # --- Availability & Skills ---\n",
    "    availability = Column(JSON, nullable=True)             # weekly availability\n",
    "    language_expertise = Column(JSON, nullable=True)       # {\"en\": 4.5, \"zh\": 3.0}\n",
    "    skill_score = Column(Float, nullable=True)             # overall skill score\n",
    "    skill_level = Column(String, nullable=True)           \n",
    "    qa_approval_rate = Column(Float, nullable=True)        # average QA pass rate\n",
    "    completed_task_count = Column(Integer, default=0)      # total tasks completed\n",
    "\n",
    "    # --- Relationships ---\n",
    "    uploaded_files = relationship(\"File\", back_populates=\"uploader\")\n",
    "    events = relationship(\"EventLog\", back_populates=\"user\")\n",
    "    assignments = relationship(\"Assignment\", back_populates=\"user\", cascade=\"all, delete-orphan\")\n",
    "\n",
    "    roles = relationship(\"Role\", secondary=user_roles, back_populates=\"users\")\n",
    "\n",
    "    # PM links\n",
    "    client_projects = relationship(\"Project\", back_populates=\"client_pm\")\n",
    "    # make sure our PM has access to projects and further assign annotators\n",
    "    managed_projects = relationship(\"Project\", back_populates=\"our_pm\")\n",
    "\n",
    "    # Historical job links\n",
    "    # Records which annotators have worked on this job before\n",
    "    # (for feedback loops / reassignment tracking)\n",
    "    previous_jobs = relationship(\n",
    "        \"AnnotationJob\",\n",
    "        secondary=\"job_previous_annotators\",\n",
    "        back_populates=\"previous_annotators\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b3368",
   "metadata": {},
   "source": [
    "    # --- Availability ---\n",
    "    # Store weekly availability / working hours in JSON\n",
    "    # Example:\n",
    "    # {\n",
    "    #   \"monday\": [\"09:00-12:00\", \"13:00-17:00\"],\n",
    "    #   \"tuesday\": [\"10:00-18:00\"],\n",
    "    #   \"wednesday\": []\n",
    "    # }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df817c6c",
   "metadata": {},
   "source": [
    "## 3.5 Annotation Job Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e44d4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/4022209090.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.AnnotationJob, and will be replaced in the string-lookup table.\n",
      "  class AnnotationJob(Base):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# File Annotation Job Table\n",
    "# --------------------------\n",
    "class AnnotationJob(Base):\n",
    "    __tablename__ = \"annotation_job\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    job_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    file_id = Column(Integer, ForeignKey(\"file.file_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "    project_id = Column(Integer, ForeignKey(\"project.project_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "\n",
    "    # New attributes\n",
    "    language = Column(Enum(Language, name=\"annotation_job_language_enum\"), nullable=True)\n",
    "    priority = Column(Enum(JobPriority, name=\"job_priority_enum\"), default=JobPriority.medium, nullable=False)\n",
    "\n",
    "    status = Column(Enum(AnnotationJobStatus, name=\"annotation_job_status_enum\"),\n",
    "                    default=AnnotationJobStatus.not_started, nullable=False)\n",
    "\n",
    "    review_status = Column(Enum(ReviewStatus, name=\"review_status_enum\"),\n",
    "                           default=ReviewStatus.pending, nullable=False)\n",
    "\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "    deleted_at = Column(DateTime, nullable=True)\n",
    "\n",
    "    due_date = Column(DateTime, nullable=True)\n",
    "    completed_at = Column(DateTime, nullable=True)\n",
    "\n",
    "    created_at = Column(DateTime, default=func.now(), nullable=False)\n",
    "    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "\n",
    "    # Relationships\n",
    "    file = relationship(\"File\", back_populates=\"annotation_jobs\")\n",
    "    project = relationship(\"Project\", back_populates=\"annotation_jobs\")\n",
    "\n",
    "    reviews = relationship(\"Review\", back_populates=\"job\", cascade=\"all, delete-orphan\")\n",
    "    assignments = relationship(\"Assignment\", back_populates=\"job\", cascade=\"all, delete-orphan\")\n",
    "\n",
    "    # Historical annotators (M2M self join via Assignment/User)\n",
    "    previous_annotators = relationship(\n",
    "        \"User\",\n",
    "        secondary=\"job_previous_annotators\",\n",
    "        back_populates=\"previous_jobs\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57f933",
   "metadata": {},
   "source": [
    "## 3.6 Event Log Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad50772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event Log Table\n",
    "class EventLog(Base):\n",
    "    __tablename__ = \"event_log\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    event_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    entity_type = Column(Enum(EntityType, name=\"entity_type_enum\"), nullable=False)\n",
    "    entity_id = Column(Integer, nullable=False)      # e.g. file_id\n",
    "\n",
    "    event_type = Column(Enum(EventType, name=\"event_type_enum\"), nullable=False)\n",
    "\n",
    "    user_id = Column(Integer, ForeignKey(\"user.user_id\"), nullable=True)\n",
    "    event_time = Column(DateTime, default=func.now())\n",
    "\n",
    "    user = relationship(\"User\", back_populates=\"events\")\n",
    "\n",
    "    event_metadata = Column(JSONB, nullable=True)  # use JSONB for flexible key/value storage\n",
    "\n",
    "    file_id = Column(Integer, ForeignKey(\"file.file_id\"), nullable=True)\n",
    "file = relationship(\"File\", back_populates=\"events\")\n",
    "\n",
    "file_version_id = Column(Integer, ForeignKey(\"file_version.version_id\"), nullable=True)\n",
    "file_version = relationship(\"FileVersion\", back_populates=\"events\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841251f",
   "metadata": {},
   "source": [
    "## 3.7 Review Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "115a8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Review Table\n",
    "# --------------------------\n",
    "class Review(Base):\n",
    "    __tablename__ = \"review\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    review_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # Link to the job being reviewed\n",
    "    job_id = Column(Integer, ForeignKey(\"annotation_job.job_id\"), nullable=False)\n",
    "\n",
    "    # Reviewer (user with reviewer role)\n",
    "    reviewer_id = Column(Integer, ForeignKey(\"user.user_id\"), nullable=False)\n",
    "\n",
    "    # Review decision\n",
    "    status = Column(\n",
    "        Enum(ReviewStatus, name=\"review_status_enum\"),\n",
    "        default=ReviewStatus.pending,\n",
    "        nullable=False\n",
    "    )\n",
    "\n",
    "    # Optional comments from reviewer\n",
    "    feedback = Column(Text, nullable=True)\n",
    "\n",
    "    # Audit timestamps\n",
    "    created_at = Column(DateTime, default=func.now(), nullable=False)\n",
    "    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "\n",
    "    # --------------------------\n",
    "    # Relationships\n",
    "    # --------------------------\n",
    "    job = relationship(\"AnnotationJob\", back_populates=\"reviews\")\n",
    "    reviewer = relationship(\"User\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8330cbc",
   "metadata": {},
   "source": [
    "## 3.8 Assignment Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad7d6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Assignment Table\n",
    "# --------------------------\n",
    "class Assignment(Base):\n",
    "    __tablename__ = \"assignment\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    assignment_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # Link to the annotation job\n",
    "    job_id = Column(Integer, ForeignKey(\"annotation_job.job_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "\n",
    "    # Who is assigned\n",
    "    user_id = Column(Integer, ForeignKey(\"user.user_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "\n",
    "    # Role in this job (annotator, reviewer, qc)\n",
    "    role = Column(Enum(AssignmentRole, name=\"assignment_role_enum\"), nullable=False)\n",
    "\n",
    "    # Status of this assignment (separate from job status)\n",
    "    status = Column(String, default=\"assigned\")  \n",
    "    # e.g. assigned, accepted, in_progress, completed\n",
    "\n",
    "    # Audit fields\n",
    "    assigned_at = Column(DateTime, default=func.now(), nullable=False)\n",
    "    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "\n",
    "    # Relationships\n",
    "    job = relationship(\"AnnotationJob\", back_populates=\"assignments\")\n",
    "    user = relationship(\"User\", back_populates=\"assignments\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ff8b7",
   "metadata": {},
   "source": [
    "## 3.9 Role&Permission Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08ce1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Role Table\n",
    "# --------------------------\n",
    "class Role(Base):\n",
    "    __tablename__ = \"role\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    role_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    name = Column(String, unique=True, nullable=False)   # e.g. \"organization_admin\", \"pm\", \"annotator\", \"reviewer\"\n",
    "\n",
    "    # Relationships\n",
    "    users = relationship(\"User\", secondary=user_roles, back_populates=\"roles\")\n",
    "    permissions = relationship(\"Permission\", secondary=role_permissions, back_populates=\"roles\")\n",
    "\n",
    "# --------------------------\n",
    "# Permission Table\n",
    "# --------------------------\n",
    "class Permission(Base):\n",
    "    __tablename__ = \"permission\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    permission_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    name = Column(String, unique=True, nullable=False)   # e.g. \"upload_file\", \"assign_job\", \"review_annotation\"\n",
    "\n",
    "    # Relationships\n",
    "    roles = relationship(\"Role\", secondary=role_permissions, back_populates=\"permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1f4e2",
   "metadata": {},
   "source": [
    "## 3.10 Organization Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9932e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Organization Table\n",
    "# ------------------------------\n",
    "class Organization(Base):\n",
    "    __tablename__ = \"organization\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    org_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    name = Column(String, unique=True, nullable=False)   # e.g. \"Acme Corp\"\n",
    "    description = Column(Text, nullable=True)            # optional, for notes\n",
    "    date_created = Column(DateTime, default=func.now(), nullable=False)\n",
    "    date_updated = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "\n",
    "    # Relationships\n",
    "    users = relationship(\"User\", back_populates=\"organization\")\n",
    "    projects = relationship(\"Project\", back_populates=\"organization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088bf58",
   "metadata": {},
   "source": [
    "## 3.11 Export / Report tables\n",
    "stores generated ZIPs or audit PDFs, those should also have an S3 pointer (storage_path)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15be445",
   "metadata": {},
   "source": [
    "cascade behavior:    \n",
    "If an export log is deleted, should the join rows in exported_file also be deleted?    \n",
    "Usually yes ‚Üí add cascade=\"all, delete-orphan\" on ExportedFile if you model it as a class.    \n",
    "If you keep exported_file as a raw Table, SQLAlchemy will handle cleanup when ExportLog is deleted.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbed3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportLog(Base):\n",
    "    __tablename__ = \"export_log\"\n",
    "\n",
    "    export_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    project_id = Column(Integer, ForeignKey(\"project.project_id\"), nullable=False)\n",
    "    requested_by = Column(Integer, ForeignKey(\"user.user_id\"), nullable=False)\n",
    "\n",
    "    # Where the final package (ZIP, PDF, TAR, etc.) lives in S3/MinIO\n",
    "    storage_path = Column(String, nullable=False)\n",
    "\n",
    "    # Optional metadata\n",
    "    checksum = Column(String, nullable=True)\n",
    "    #included_file_ids = Column(JSON, nullable=True)  # list of files packaged\n",
    "    #included_versions = Column(JSON, nullable=True)  # if version-level tracking matters\n",
    "\n",
    "    status = Column(Enum(\"pending\", \"completed\", \"failed\", name=\"export_status_enum\"), default=\"pending\")\n",
    "\n",
    "    date_requested = Column(DateTime, default=func.now(), nullable=False)\n",
    "    date_completed = Column(DateTime, nullable=True)\n",
    "\n",
    "    # Relationships\n",
    "    project = relationship(\"Project\", back_populates=\"exports\")\n",
    "    requested_user = relationship(\"User\", foreign_keys=[requested_by])\n",
    "    file_versions = relationship(\n",
    "    \"FileVersion\",\n",
    "    secondary=\"exported_file\",    # uses the join table\n",
    "    back_populates=\"exports\"\n",
    "    )\n",
    "    exported_files = relationship(\n",
    "        \"ExportedFile\",\n",
    "        back_populates=\"export\",\n",
    "        cascade=\"all, delete-orphan\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MyProject Env)",
   "language": "python",
   "name": "myproject_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
